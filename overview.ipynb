{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCQY7jpBfMur"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "z6X9omPnfO_h"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1xIRPtY0E1w"
   },
   "source": [
    "# Keras overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyOjQZHhZxaA"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/overview\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/keras/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/keras/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUJTep_x5-R8"
   },
   "source": [
    "本指南将介绍入门 Keras 所需的基础知识。阅读本文需要约 10 分钟。\n",
    "<!--\n",
    "This guide gives you the basics to get started with Keras. It's a 10-minute read.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsK5aF2xZ-40"
   },
   "source": [
    "## 导入 tf.keras\n",
    "\n",
    "`tf.keras` 是 [Keras API 规范](https://keras.io)的 TensorFlow 实现。这是一个构建、训练模型的高级 API，包含对 TensorFlow 独特功能的最佳支持，例如 [eager execution](../eager.ipynb)，`tf.data` pipelines，以及 [Estimators](../estimator.ipynb)。`tf.keras` 使得 TensorFlow 更加易用，且无须牺牲其灵活性和性能。\n",
    "\n",
    "<!--\n",
    "`tf.keras` is TensorFlow's implementation of the\n",
    "[Keras API specification](https://keras.io). This is a high-level\n",
    "API to build and train models that includes first-class support for\n",
    "TensorFlow-specific functionality, such as [eager execution](../eager.ipynb),\n",
    "`tf.data` pipelines, and [Estimators](../estimator.ipynb).\n",
    "`tf.keras` makes TensorFlow easier to use without sacrificing flexibility and\n",
    "performance.\n",
    "-->\n",
    "\n",
    "要想开始本指南，请为你的 TensorFlow 程序导入 `tf.keras`。\n",
    "\n",
    "<!--\n",
    "To get started, import `tf.keras` as part of your TensorFlow program setup:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lj03RamP0E13"
   },
   "source": [
    "`tf.keras` 能够运行任何兼容 Keras 的代码，不过需要记住：\n",
    "<!--\n",
    "`tf.keras` can run any Keras-compatible code, but keep in mind:\n",
    "-->\n",
    "\n",
    "* 最新版的 TensorFlow 中的 `tf.keras` 版本可能和 PyPI 上最新的 `keras` 的版本不一样。请检查 `tf.keras.__version__`。\n",
    "\n",
    "<!--\n",
    "* The `tf.keras` version in the latest TensorFlow release might not be the same\n",
    "  as the latest `keras` version from PyPI. Check `tf.keras.__version__`.\n",
    "-->\n",
    "\n",
    "* 在[保存模型的权重](./save_and_serialize.ipynb)时，`tf.keras` 默认选取 [checkpoint 格式](../checkpoint.ipynb)。传入 `save_format='h5'` 参数以使用 HDF5（或者传入一个以 `.h5` 为扩展名的文件）。\n",
    "\n",
    "<!--\n",
    "* When [saving a model's weights](./save_and_serialize.ipynb), `tf.keras` defaults to the\n",
    "  [checkpoint format](../checkpoint.ipynb). Pass `save_format='h5'` to\n",
    "  use HDF5 (or pass a filename that ends in `.h5`).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e1LPcXx0gR6"
   },
   "source": [
    "## 构建一个简单的模型\n",
    "<!--\n",
    "## Build a simple model\n",
    "-->\n",
    "\n",
    "### 顺序模型 Sequential model\n",
    "<!--\n",
    "### Sequential model\n",
    "-->\n",
    "\n",
    "在 Keras 中，你需要组合*层*来构建*模型*。一个模型（一般）是一个由层构成的图。最常见的一种模型是由层堆叠而成的：即 `tf.keras.Sequential` 模型。\n",
    "<!--\n",
    "In Keras, you assemble *layers* to build *models*. A model is (usually) a graph\n",
    "of layers. The most common type of model is a stack of layers: the\n",
    "`tf.keras.Sequential` model.\n",
    "-->\n",
    "\n",
    "下面的代码构建了一个简单的、全联接的网络（多层感知机）：\n",
    "<!--\n",
    "To build a simple, fully-connected network (i.e. multi-layer perceptron):\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add an output layer with 10 output units:\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2oH0-cxH7YA"
   },
   "source": [
    "你可以在[这里](https://www.tensorflow.org/tutorials/quickstart/beginner)找到一个完整、简单的案例，来了解如何使用 Sequential models。\n",
    "<!--\n",
    "You can find a complete, short example of how to use Sequential models [here](https://www.tensorflow.org/tutorials/quickstart/beginner).\n",
    "-->\n",
    "\n",
    "要想学习如何构建比 Sequential models 更为高级的模型，参看：\n",
    "<!--\n",
    "To learn about building more advanced models than Sequential models, see:\n",
    "-->\n",
    "- [Guide to the Keras Functional API](./functional.ipynb)\n",
    "- [Guide to writing layers and models from scratch with subclassing](./custom_layers_and_models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ztyTipu0E18"
   },
   "source": [
    "### 配置层\n",
    "\n",
    "<!--\n",
    "### Configure the layers\n",
    "-->\n",
    "\n",
    "有很多 `tf.keras.layers` 可供我们使用。它们中大部分有着相同的构造函数参数：\n",
    "\n",
    "<!--\n",
    "There are many `tf.keras.layers` available. Most of them share some common constructor\n",
    "arguments:\n",
    "-->\n",
    "\n",
    "* `activation`：为层设置激活函数。参数应当是一个内置函数的名字，或者是一个可调用对象。默认情况下不会应用任何激活函数。\n",
    "\n",
    "<!--\n",
    "* `activation`: Set the activation function for the layer. This parameter is\n",
    "  specified by the name of a built-in function or as a callable object. By\n",
    "  default, no activation is applied.\n",
    "-->\n",
    "\n",
    "* `kernel_initializer` 和 `bias_initializer`：用于创建层的权重（kernel 和 bias）的初始化方案。该参数是一个名字或者一个可调用对象。默认是 `\"Glorot uniform\"` 初始化器。\n",
    "\n",
    "<!--\n",
    "* `kernel_initializer` and `bias_initializer`: The initialization schemes\n",
    "  that create the layer's weights (kernel and bias). This parameter is a name or\n",
    "  a callable object. This defaults to the `\"Glorot uniform\"` initializer.\n",
    "-->\n",
    "\n",
    "* `kernel_regularizer` 和 `bias_regularizer`：应用层的权重（kernel 和 bias）的正则化方案，例如 L1 和 L2 正则化。默认情况下不应用任何正则化。\n",
    "\n",
    "<!--\n",
    "* `kernel_regularizer` and `bias_regularizer`: The regularization schemes\n",
    "  that apply the layer's weights (kernel and bias), such as L1 or L2\n",
    "  regularization. By default, no regularization is applied.\n",
    "-->\n",
    "\n",
    "下面的例子使用构造函数参数来初始化 `tf.keras.layers.Dense` 层：\n",
    "<!--\n",
    "The following instantiates `tf.keras.layers.Dense` layers using constructor\n",
    "arguments:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7fbbf11dc5d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a relu layer:\n",
    "layers.Dense(64, activation='relu')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.nn.relu)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NR6reyk0E2A"
   },
   "source": [
    "## 训练和评估 Train and evaluate\n",
    "<!--\n",
    "## Train and evaluate\n",
    "-->\n",
    "\n",
    "### 建立训练\n",
    "<!--\n",
    "### Set up training\n",
    "-->\n",
    "\n",
    "在模型构建好之后，通过调用 `compile` 方法来配置模型的学习过程：\n",
    "<!--\n",
    "After the model is constructed, configure its learning process by calling the\n",
    "`compile` method:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Adds a densely-connected layer with 64 units to the model:\n",
    "    layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    # Add another:\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    # Add an output layer with 10 output units:\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HG-RAa9F0E2D"
   },
   "source": [
    "`tf.keras.Model.compile` 接受三个重要的参数：\n",
    "<!--\n",
    "`tf.keras.Model.compile` takes three important arguments:\n",
    "-->\n",
    "\n",
    "* `optimizer`：该对象指定了训练的过程。请为其传入 `tf.keras.optimizers` 里的优化器**对象**，例如 `tf.keras.optimizers.Adam` 或 `tf.keras.optimizers.SGD`。如果你想使用优化器的默认参数来构造优化器对象并传入，你也可以使用字符串来指定优化器，例如 `'adam'` 或者 `'sgd'`。\n",
    "\n",
    "<!--\n",
    "* `optimizer`: This object specifies the training procedure. Pass it optimizer\n",
    "  **instances** from the `tf.keras.optimizers` module, such as\n",
    "  `tf.keras.optimizers.Adam` or\n",
    "  `tf.keras.optimizers.SGD`. If you just want to use the default parameters, you can also specify optimizers via strings, such as `'adam'` or `'sgd'`.\n",
    "-->\n",
    "\n",
    "* `loss`：即损失函数，优化过程需要最小化的函数。常见的选项包括均方误差（`mse`），`categorical_crossentropy`，以及 `binary_crossentropy`。损失函数由名字或者通过传入 `tf.keras.losses` 模块里的可调用对象来指定。\n",
    "\n",
    "<!--\n",
    "* `loss`: The function to minimize during optimization. Common choices include\n",
    "  mean square error (`mse`), `categorical_crossentropy`, and\n",
    "  `binary_crossentropy`. Loss functions are specified by name or by\n",
    "  passing a callable object from the `tf.keras.losses` module.\n",
    "-->\n",
    "\n",
    "* `metrics`：指标，用于监控训练过程。它们是字符串名称或者是 `tf.keras.metrics` 模块里的 callables。\n",
    "\n",
    "<!--\n",
    "* `metrics`: Used to monitor training. These are string names or callables from\n",
    "  the `tf.keras.metrics` module.\n",
    "-->\n",
    "\n",
    "* 此外，要想确保模型以 eager 模式训练和评估，你可以传入 `run_eagerly=True` 作为编译参数。\n",
    "\n",
    "<!--\n",
    "* Additionally, to make sure the model trains and evaluates eagerly, you can make sure to pass `run_eagerly=True` as a parameter to compile.\n",
    "-->\n",
    "\n",
    "\n",
    "下面展示了一些配置训练模型的例子：\n",
    "<!--\n",
    "The following shows a few examples of configuring a model for training:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjI5rbi80E2G"
   },
   "source": [
    "### 使用 NumPy 数据训练\n",
    "<!--\n",
    "### Train from NumPy data\n",
    "-->\n",
    "\n",
    "对于小型数据集，请使用存储在内存中的 [NumPy]() 数组来训练和评估模型。模型使用 `fit` 方法来“拟合”（\"fit\"）训练数据：\n",
    "<!--\n",
    "For small datasets, use in-memory [NumPy](https://www.numpy.org/)\n",
    "arrays to train and evaluate a model. The model is \"fit\" to the training data\n",
    "using the `fit` method:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s 371us/sample - loss: 248.1703 - accuracy: 0.1020\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 1099.8311 - accuracy: 0.0980\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 2162.2666 - accuracy: 0.0850\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 3632.7083 - accuracy: 0.0950\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 5551.9390 - accuracy: 0.1150\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 7563.1280 - accuracy: 0.1100\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 10013.2830 - accuracy: 0.1100\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 12934.9943 - accuracy: 0.0960\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 15701.5869 - accuracy: 0.1040\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 18901.7827 - accuracy: 0.0880\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 23056.2304 - accuracy: 0.0910\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 27195.0815 - accuracy: 0.0940\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 30639.5891 - accuracy: 0.1120\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 36078.6813 - accuracy: 0.0970\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 41299.9646 - accuracy: 0.0930\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 46884.3590 - accuracy: 0.0850\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 52877.0201 - accuracy: 0.0980\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 57111.7668 - accuracy: 0.0950\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 61186.1366 - accuracy: 0.1070\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 69948.1923 - accuracy: 0.0880\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 77695.6573 - accuracy: 0.1000\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 82011.8754 - accuracy: 0.1210\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 94005.0538 - accuracy: 0.1050\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 97745.6247 - accuracy: 0.0940\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 110386.8066 - accuracy: 0.0980\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 114860.2316 - accuracy: 0.1070\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 123348.6273 - accuracy: 0.1030\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 133001.1424 - accuracy: 0.1010\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 141605.7583 - accuracy: 0.1070\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 153836.1905 - accuracy: 0.1000\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 161648.9210 - accuracy: 0.0910\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 172068.3185 - accuracy: 0.1000\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 181706.7054 - accuracy: 0.1010\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 187711.5500 - accuracy: 0.1040\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 207520.6478 - accuracy: 0.1100\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 212387.1000 - accuracy: 0.1100\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 228302.4215 - accuracy: 0.1040\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 247584.9380 - accuracy: 0.0960\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 250019.2454 - accuracy: 0.0970\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 260432.6215 - accuracy: 0.1110\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 281120.6958 - accuracy: 0.0980\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 292634.4672 - accuracy: 0.0890\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 296948.4761 - accuracy: 0.1050\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 319624.3920 - accuracy: 0.1070\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 315977.2500 - accuracy: 0.1030\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 347056.6682 - accuracy: 0.0830\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 367466.5775 - accuracy: 0.1040\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 387088.5125 - accuracy: 0.1000\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 398362.7975 - accuracy: 0.1000\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 409021.3862 - accuracy: 0.1090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbf15a2750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-pnVaFe0E2N"
   },
   "source": [
    "`tf.keras.Model.fit` 接受三个重要的参数：\n",
    "<!--\n",
    "`tf.keras.Model.fit` takes three important arguments:\n",
    "-->\n",
    "\n",
    "* `epochs`：训练过程被组合成多个*周期*。一个周期是对所有输入数据的一次迭代（这里“所有输入数据”指的是一个批次里的数据）。\n",
    "\n",
    "<!--\n",
    "* `epochs`: Training is structured into *epochs*. An epoch is one iteration over\n",
    "  the entire input data (this is done in smaller batches).\n",
    "-->\n",
    "\n",
    "* `batch_size`：传入 NumPy 数据时，模型将数据切成较小的批次，并在训练过程中对这些批次进行迭代。该整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能会较小。\n",
    "\n",
    "<!--\n",
    "* `batch_size`: When passed NumPy data, the model slices the data into smaller\n",
    "  batches and iterates over these batches during training. This integer\n",
    "  specifies the size of each batch. Be aware that the last batch may be smaller\n",
    "  if the total number of samples is not divisible by the batch size.\n",
    "-->\n",
    "\n",
    "* `validation_data`：在对模型进行原型制作时，你希望能轻松地在某些验证数据上监视模型性能。传递此参数（由输入数据和标签组成的元组）可以使模型在每个训练周期结束时以推断模式（inference mode）显示模型在所传递的验证数据集上的损失和指标。\n",
    "\n",
    "<!--\n",
    "* `validation_data`: When prototyping a model, you want to easily monitor its\n",
    "  performance on some validation data. Passing this argument—a tuple of inputs\n",
    "  and labels—allows the model to display the loss and metrics in inference mode\n",
    "  for the passed data, at the end of each epoch.\n",
    "-->\n",
    "\n",
    "下面是一个使用 `validation_data` 的例子：\n",
    "<!--\n",
    "Here's an example using `validation_data`:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 419393.2990 - accuracy: 0.0880 - val_loss: 300127.7025 - val_accuracy: 0.1300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 422716.0370 - accuracy: 0.0970 - val_loss: 571856.4950 - val_accuracy: 0.1300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 458636.2720 - accuracy: 0.1150 - val_loss: 378919.2350 - val_accuracy: 0.1100\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 471186.8805 - accuracy: 0.1000 - val_loss: 503599.4688 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 496754.7103 - accuracy: 0.1040 - val_loss: 508491.4950 - val_accuracy: 0.0700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 506077.9167 - accuracy: 0.1180 - val_loss: 481604.0000 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 507225.7310 - accuracy: 0.1040 - val_loss: 683180.1200 - val_accuracy: 0.1100\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 549980.1370 - accuracy: 0.0970 - val_loss: 631952.6800 - val_accuracy: 0.1100\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 545913.3225 - accuracy: 0.1120 - val_loss: 611851.9313 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 573261.5385 - accuracy: 0.1060 - val_loss: 912740.6150 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbf1f1f610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6ImyXzz0E2Q"
   },
   "source": [
    "### 使用 `tf.data` 数据集进行训练\n",
    "<!--\n",
    "### Train from tf.data datasets\n",
    "-->\n",
    "\n",
    "对于大规模数据集或者多设备上的训练，请使用 [Datasets API](../data.ipynb)。这需要传递一个 `tf.data.Dataset` 实例给 `fit` 方法：\n",
    "<!--\n",
    "Use the [Datasets API](../data.ipynb) to scale to large datasets\n",
    "or multi-device training. Pass a `tf.data.Dataset` instance to the `fit`\n",
    "method:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 32), (None, 10)), types: (tf.float64, tf.float64)>\n",
      "Train for 32 steps\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 596764.4374 - accuracy: 0.1020\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 623741.0719 - accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 619684.7495 - accuracy: 0.0810\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 646420.9913 - accuracy: 0.0920\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 677723.5886 - accuracy: 0.0880\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 695414.9624 - accuracy: 0.1080\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 699082.5456 - accuracy: 0.1040\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 704932.6676 - accuracy: 0.1020\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 783390.5352 - accuracy: 0.0970\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 777909.7650 - accuracy: 0.0880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbf1f18f10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "print(dataset)\n",
    "\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7BcMHkB0E2U"
   },
   "source": [
    "由于 `Dataset` 会产生数据批次，因此此代码段不需要给定 `batch_size`。\n",
    "<!--\n",
    "Since the `Dataset` yields batches of data, this snippet does not require a `batch_size`.\n",
    "-->\n",
    "\n",
    "数据集也可以用于验证：\n",
    "<!--\n",
    "Datasets can also be used for validation:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 32 steps, validate for 4 steps\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 790067.1488 - accuracy: 0.1110 - val_loss: 710189.5000 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 810423.1309 - accuracy: 0.0890 - val_loss: 1025312.4062 - val_accuracy: 0.1300\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 841993.7541 - accuracy: 0.0970 - val_loss: 1031089.3438 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 860692.6692 - accuracy: 0.1050 - val_loss: 826302.7031 - val_accuracy: 0.1100\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 887857.3061 - accuracy: 0.1070 - val_loss: 976127.7656 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 926653.2637 - accuracy: 0.0950 - val_loss: 930464.8594 - val_accuracy: 0.0900\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 904975.7242 - accuracy: 0.1000 - val_loss: 1103748.5625 - val_accuracy: 0.0900\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 982363.7865 - accuracy: 0.1030 - val_loss: 1546460.0938 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 994246.5558 - accuracy: 0.1000 - val_loss: 1218739.5625 - val_accuracy: 0.0900\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 975037.8960 - accuracy: 0.1040 - val_loss: 1022475.0625 - val_accuracy: 0.1300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbf1f11490>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=10,\n",
    "          validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgGdlXso0E2X"
   },
   "source": [
    "### 评估和预测\n",
    "<!--\n",
    "### Evaluate and predict\n",
    "-->\n",
    "\n",
    "`tf.keras.Model.evaluate` 和 `tf.keras.Model.predict` 方法可以使用 NumPy 数据和 `tf.data.Dataset`。\n",
    "<!--\n",
    "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy\n",
    "data and a `tf.data.Dataset`.\n",
    "-->\n",
    "\n",
    "下面展示了对于所给的数据，如何以推断模式（inference-mode）*评估*损失和指标。\n",
    "<!--\n",
    "Here's how to *evaluate* the inference-mode loss and metrics for the data provided:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 28us/sample - loss: 1067639.8960 - accuracy: 0.1000\n",
      "32/32 [==============================] - 0s 953us/step - loss: 1068890.8574 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1068890.857421875, 0.1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Numpy arrays\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)\n",
    "\n",
    "# With a Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "model.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method evaluate in module tensorflow.python.keras.engine.training:\n",
      "\n",
      "evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False) method of tensorflow.python.keras.engine.sequential.Sequential instance\n",
      "    Returns the loss value & metrics values for the model in test mode.\n",
      "    \n",
      "    Computation is done in batches.\n",
      "    \n",
      "    Arguments:\n",
      "        x: Input data. It could be:\n",
      "          - A Numpy array (or array-like), or a list of arrays\n",
      "            (in case the model has multiple inputs).\n",
      "          - A TensorFlow tensor, or a list of tensors\n",
      "            (in case the model has multiple inputs).\n",
      "          - A dict mapping input names to the corresponding array/tensors,\n",
      "            if the model has named inputs.\n",
      "          - A `tf.data` dataset.\n",
      "          - A generator or `keras.utils.Sequence` instance.\n",
      "          A more detailed description of unpacking behavior for iterator types\n",
      "          (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      "          for iterator-like inputs` section of `Model.fit`.\n",
      "        y: Target data. Like the input data `x`,\n",
      "          it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "          It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "          tensor targets, or inversely).\n",
      "          If `x` is a dataset, generator or\n",
      "          `keras.utils.Sequence` instance, `y` should not be specified (since\n",
      "          targets will be obtained from the iterator/dataset).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of symbolic tensors, dataset,\n",
      "            generators, or `keras.utils.Sequence` instances (since they generate\n",
      "            batches).\n",
      "        verbose: 0 or 1. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar.\n",
      "        sample_weight: Optional Numpy array of weights for\n",
      "            the test samples, used for weighting the loss function.\n",
      "            You can either pass a flat (1D)\n",
      "            Numpy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples),\n",
      "            or in the case of temporal data,\n",
      "            you can pass a 2D array with shape\n",
      "            `(samples, sequence_length)`,\n",
      "            to apply a different weight to every timestep of every sample.\n",
      "            In this case you should make sure to specify\n",
      "            `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      "            supported when `x` is a dataset, instead pass\n",
      "            sample weights as the third element of `x`.\n",
      "        steps: Integer or `None`.\n",
      "            Total number of steps (batches of samples)\n",
      "            before declaring the evaluation round finished.\n",
      "            Ignored with the default value of `None`.\n",
      "            If x is a `tf.data` dataset and `steps` is\n",
      "            None, 'evaluate' will run until the dataset is exhausted.\n",
      "            This argument is not supported with array inputs.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during evaluation.\n",
      "            See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "            input only. Maximum size for the generator queue.\n",
      "            If unspecified, `max_queue_size` will default to 10.\n",
      "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "            only. Maximum number of processes to spin up when using\n",
      "            process-based threading. If unspecified, `workers` will default\n",
      "            to 1. If 0, will execute the generator on the main thread.\n",
      "        use_multiprocessing: Boolean. Used for generator or\n",
      "            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "            threading. If unspecified, `use_multiprocessing` will default to\n",
      "            `False`. Note that because this implementation relies on\n",
      "            multiprocessing, you should not pass non-picklable arguments to\n",
      "            the generator as they can't be passed easily to children processes.\n",
      "    \n",
      "    See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      "    `Model.fit`.\n",
      "    \n",
      "    Returns:\n",
      "        Scalar test loss (if the model has a single output and no metrics)\n",
      "        or list of scalars (if the model has multiple outputs\n",
      "        and/or metrics). The attribute `model.metrics_names` will give you\n",
      "        the display labels for the scalar outputs.\n",
      "    \n",
      "    Raises:\n",
      "        ValueError: in case of invalid arguments.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXUTmDfb0E2b"
   },
   "source": [
    "下面展示的是对于所给的数据，如何以推断模式（inference mode）*预测* 最后一层的输出（作为一个 NumPy array）：\n",
    "<!--\n",
    "And here's how to *predict* the output of the last layer in inference for the data provided,\n",
    "as a NumPy array:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.3244474e+08 5.3243904e+08 5.3246621e+08 ... 5.3214819e+08\n",
      "  5.3249341e+08 5.3243414e+08]\n",
      " [5.2680662e+08 5.2680118e+08 5.2682790e+08 ... 5.2651325e+08\n",
      "  5.2685488e+08 5.2679632e+08]\n",
      " [3.7911248e+08 3.7910848e+08 3.7912784e+08 ... 3.7890128e+08\n",
      "  3.7914723e+08 3.7910502e+08]\n",
      " ...\n",
      " [4.9461078e+08 4.9460554e+08 4.9463075e+08 ... 4.9433523e+08\n",
      "  4.9465597e+08 4.9460102e+08]\n",
      " [4.1955075e+08 4.1954634e+08 4.1956765e+08 ... 4.1931702e+08\n",
      "  4.1958909e+08 4.1954246e+08]\n",
      " [4.5267162e+08 4.5266691e+08 4.5268992e+08 ... 4.5241949e+08\n",
      "  4.5271306e+08 4.5266275e+08]]\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data, batch_size=32)\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuTb71gYILLG"
   },
   "source": [
    "有关训练和评估的完整指南，包括如何从头开始编写自定义的训练循环，请参阅[训练和评估指南](./train_and_evaluate.ipynb)。\n",
    "<!--\n",
    "For a complete guide on training and evaluation, including how to write custom training loops from scratch, see the [guide to training and evaluation](./train_and_evaluate.ipynb).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fzEOW4Cn0E2h"
   },
   "source": [
    "## 构建复杂的模型\n",
    "<!--\n",
    "## Build complex models\n",
    "-->\n",
    "\n",
    "### 函数式 API\n",
    "<!--\n",
    "### The Functional API\n",
    "-->\n",
    "\n",
    "`tf.keras.Sequential` 模型是对层的简单堆叠，它不能表示任意的模型。请使用 [Keras 函数式 API](./functional.ipynb) 来构建复杂的模型拓扑，如：\n",
    "<!--\n",
    "The `tf.keras.Sequential` model is a simple stack of layers that cannot\n",
    "represent arbitrary models. Use the\n",
    "[Keras functional API](./functional.ipynb)\n",
    "to build complex model topologies such as:\n",
    "-->\n",
    "\n",
    "* 多输入模型，\n",
    "* 多输出模型，\n",
    "* 有共享层的模型（同一个层被调用多次），\n",
    "* 有非顺序数据流的模型（例如存在剩余连接 residual connections 的情况）。\n",
    "\n",
    "<!--\n",
    "* Multi-input models,\n",
    "* Multi-output models,\n",
    "* Models with shared layers (the same layer called several times),\n",
    "* Models with non-sequential data flows (e.g. residual connections).\n",
    "-->\n",
    "\n",
    "使用函数式 API 构建模型的步骤如下：\n",
    "<!--\n",
    "Building a model with the functional API works like this:\n",
    "-->\n",
    "\n",
    "1. 一个层的实例是可调用的，并且返回一个张量。\n",
    "2. 输入张量和输出张量将被用于定义 `tf.keras.Model` 实例。\n",
    "3. 就像对 `Sequential` 模型一样训练该模型.\n",
    "\n",
    "<!--\n",
    "1. A layer instance is callable and returns a tensor.\n",
    "2. Input tensors and output tensors are used to define a `tf.keras.Model`\n",
    "   instance.\n",
    "3. This model is trained just like the `Sequential` model.\n",
    "-->\n",
    "\n",
    "下面这个例子使用函数式 API 来构建一个简单的全连接网络：\n",
    "<!--\n",
    "The following example uses the functional API to build a simple, fully-connected\n",
    "network:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'tensorflow.python.framework.ops.Tensor'>, <class 'tensorflow.python.framework.tensor_like._TensorLike'>, <class 'object'>)\n",
      "(<class 'tensorflow.python.framework.ops.Tensor'>, <class 'tensorflow.python.framework.tensor_like._TensorLike'>, <class 'object'>)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))  # Returns an input placeholder\n",
    "\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(10)(x)\n",
    "\n",
    "print(type(inputs).__mro__)\n",
    "print(type(predictions).__mro__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFmspHeG1_W7"
   },
   "source": [
    "给定输入和输出，以此初始化模型。\n",
    "<!--\n",
    "Instantiate the model given inputs and outputs.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 427us/sample - loss: 11.9857 - accuracy: 0.1050\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 15.8099 - accuracy: 0.1110\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 22.2672 - accuracy: 0.1020\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 30.3677 - accuracy: 0.1110\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 39.2023 - accuracy: 0.1030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbf217b410>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcKSLH3i0E2k"
   },
   "source": [
    "### 模型子类化\n",
    "<!--\n",
    "### Model subclassing\n",
    "-->\n",
    "\n",
    "可以通过子类化 `tf.keras.Model` 并定义你自己的 forward pass 来创建一个完全可自行定制的模型。在 `__init__` 方法里创建层，并将它们设为类实例的属性。在 `call` 方法里定义 forward pass。\n",
    "<!--\n",
    "Build a fully-customizable model by subclassing `tf.keras.Model` and defining\n",
    "your own forward pass. Create layers in the `__init__` method and set them as\n",
    "attributes of the class instance. Define the forward pass in the `call` method.\n",
    "-->\n",
    "\n",
    "在 [eager execution](../eager.ipynb) 启用时，模型子类化尤其有用，因为它允许我们强制性地编写 forward pass。\n",
    "<!--\n",
    "Model subclassing is particularly useful when\n",
    "[eager execution](../eager.ipynb) is enabled, because it allows the forward pass\n",
    "to be written imperatively.\n",
    "-->\n",
    "\n",
    "注意：如果你需要你的模型*始终*强制运行，你可以在调用 `super` 构造函数时设置 `dynamic=True`。\n",
    "<!--\n",
    "Note: if you need your model to *always* run imperatively, you can set `dynamic=True` when calling the `super` constructor.\n",
    "-->\n",
    "\n",
    "> 重点：请为模型选择正确的 API。虽然模型子类化为我们提供了更大的灵活性，但这样的代价是具有更高的复杂度，而且用户有更大几率带来错误。如果可能的话，请使用函数式 API。\n",
    "<!--\n",
    "> Key Point: Use the right API for the job. While model subclassing offers\n",
    "flexibility, it comes at a cost of greater complexity and more opportunities for\n",
    "user errors. If possible, prefer the functional API.\n",
    "-->\n",
    "\n",
    "下面这个例子展示了一个子类化的 `tf.keras.Model`，它使用了传统的 forward pass，不需要被强制运行：\n",
    "<!--\n",
    "The following example shows a subclassed `tf.keras.Model` using a custom forward\n",
    "pass that does not have to be run imperatively:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        # Define your layers here.\n",
    "        self.dense_1 = layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define your forward pass here,\n",
    "        # using layers you previously defined (in `__init__`).\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ShDD4fv72KGc"
   },
   "source": [
    "实例化这个新的模型类：\n",
    "<!--\n",
    "Instantiate the new model class:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 297us/sample - loss: 12.5955 - accuracy: 0.0900\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 14.1507 - accuracy: 0.0840\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 15.9554 - accuracy: 0.0890\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 17.6693 - accuracy: 0.0920\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 19.5837 - accuracy: 0.0960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbf3da1d50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqRQiKj20E2o"
   },
   "source": [
    "### 自定义层\n",
    "<!--\n",
    "### Custom layers\n",
    "-->\n",
    "\n",
    "通过继承 `tf.keras.layers.Layer` 并实现以下方法来创建自定义层：\n",
    "<!--\n",
    "Create a custom layer by subclassing `tf.keras.layers.Layer` and implementing\n",
    "the following methods:\n",
    "-->\n",
    "\n",
    "* `__init__`：定义该层要使用的子层（可选）。\n",
    "\n",
    "<!--\n",
    "* `__init__`: Optionally define sublayers to be used by this layer.\n",
    "-->\n",
    "\n",
    "* `build`：创建图层的权重。使用 `add_weight` 方法添加权重。\n",
    "\n",
    "<!--\n",
    "* `build`: Create the weights of the layer. Add weights with the `add_weight`\n",
    "  method.\n",
    "-->\n",
    "\n",
    "* `call`：定义 forward pass。\n",
    "\n",
    "<!--\n",
    "* `call`: Define the forward pass.\n",
    "-->\n",
    "\n",
    "* （可选）可以通过实现 `get_config` 方法和 `from_config` 类方法来序列化层。\n",
    "\n",
    "<!--\n",
    "* Optionally, a layer can be serialized by implementing the `get_config` method\n",
    "  and the `from_config` class method.\n",
    "-->\n",
    "\n",
    "下面一个自定义层的示例，它实现了输入和核矩阵之间的 `matmul`：\n",
    "<!--\n",
    "Here's an example of a custom layer that implements a `matmul` of an input with\n",
    "a kernel matrix:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7BFnIHr2WNc"
   },
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wXDRgXV2ZrF"
   },
   "source": [
    "使用你的自定义层来创建一个模型：\n",
    "<!--\n",
    "Create a model using your custom layer:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqH-cY0h0E2p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 204us/sample - loss: 11.5141 - accuracy: 0.1170\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 11.5142 - accuracy: 0.1150\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 11.5142 - accuracy: 0.1170\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 11.5136 - accuracy: 0.1170\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 11.5137 - accuracy: 0.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbf423f950>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    MyLayer(10)\n",
    "])\n",
    "\n",
    "# The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llipvR5wIl_t"
   },
   "source": [
    "请在[从头编写层和模型的指南](./custom_layers_and_models.ipynb)中了解更多关于通过子类化来从头创建新的层和模型的知识。\n",
    "<!--\n",
    "Learn more about creating new layers and models from scratch with subclassing in the [Guide to writing layers and models from scratch](./custom_layers_and_models.ipynb).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lu8cc3AJ0E2v"
   },
   "source": [
    "## 回调\n",
    "<!--\n",
    "## Callbacks\n",
    "-->\n",
    "\n",
    "回调是传递给模型以便在训练中自定义和扩展模型行为的对象。您可以编写自己的自定义回调，也可以使用内置的 `tf.keras.callbacks`，包括：\n",
    "<!--\n",
    "A callback is an object passed to a model to customize and extend its behavior\n",
    "during training. You can write your own custom callback, or use the built-in\n",
    "`tf.keras.callbacks` that include:\n",
    "-->\n",
    "\n",
    "* `tf.keras.callbacks.ModelCheckpoint`：在固定的时间间隔将模型的检查点保存。\n",
    "\n",
    "<!--\n",
    "* `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at\n",
    "  regular intervals.\n",
    "-->\n",
    "\n",
    "* `tf.keras.callbacks.LearningRateScheduler`：动态更改学习率（learning rate）。\n",
    "\n",
    "<!--\n",
    "* `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning\n",
    "  rate.\n",
    "-->\n",
    "\n",
    "* `tf.keras.callbacks.EarlyStopping`：当模型在验证数据集上的性能不再提升时，中断训练。\n",
    "\n",
    "<!--\n",
    "* `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation\n",
    "  performance has stopped improving.\n",
    "-->\n",
    "\n",
    "* `tf.keras.callbacks.TensorBoard`：使用 [TensorBoard](https://tensorflow.org/tensorboard) 监视模型的行为。\n",
    "\n",
    "<!--\n",
    "* `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using\n",
    "  [TensorBoard](https://tensorflow.org/tensorboard).\n",
    "-->\n",
    "\n",
    "要使用 `tf.keras.callbacks.Callback`，请将其传递给模型的 `fit` 方法：\n",
    "\n",
    "<!--\n",
    "To use a `tf.keras.callbacks.Callback`, pass it to the model's `fit` method:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdYwzSYV0E2v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 11.5135 - accuracy: 0.1200 - val_loss: 11.5388 - val_accuracy: 0.0500\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 11.5135 - accuracy: 0.1210 - val_loss: 11.5400 - val_accuracy: 0.0400\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.5137 - accuracy: 0.1170 - val_loss: 11.5372 - val_accuracy: 0.0400\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 11.5130 - accuracy: 0.1220 - val_loss: 11.5378 - val_accuracy: 0.0500\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 11.5133 - accuracy: 0.1210 - val_loss: 11.5386 - val_accuracy: 0.0400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbf433b710>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "    # Write TensorBoard logs to `./logs` directory\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghhaGfX62abv"
   },
   "source": [
    "<a name='save_and_restore'></a>\n",
    "## 保存和还原\n",
    "<!--\n",
    "## Save and restore\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnl7K-aI0E2z"
   },
   "source": [
    "<a name=\"weights_only\"></a>\n",
    "### 只保存权重值\n",
    "<!--\n",
    "### Save just the weights values\n",
    "-->\n",
    "\n",
    "使用 `tf.keras.Model.save_weights` 和 `tf.keras.Model.load_weights` 来保存和加载模型的权重：\n",
    "<!--\n",
    "Save and load the weights of a model using `tf.keras.Model.save_weights`:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQIANjB94fLB"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eoHJ-ny0E21"
   },
   "outputs": [],
   "source": [
    "# Save weights to a TensorFlow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Restore the model's state,\n",
    "# this requires a model with the same architecture.\n",
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u25Id3xe0E25"
   },
   "source": [
    "默认情况下，这会将模型的权重保存为 [TensorFlow checkpoint](../checkpoint.ipynb) 文件格式。权重也可以保存为 Keras HDF5 格式（Keras 的多后端实现的默认设置）：\n",
    "<!--\n",
    "By default, this saves the model's weights in the\n",
    "[TensorFlow checkpoint](../checkpoint.ipynb) file format. Weights can\n",
    "also be saved to the Keras HDF5 format (the default for the multi-backend\n",
    "implementation of Keras):\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSAYoFEd0E26"
   },
   "outputs": [],
   "source": [
    "# Save weights to a HDF5 file\n",
    "model.save_weights('my_model.h5', save_format='h5')\n",
    "\n",
    "# Restore the model's state\n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mje_yKL10E29"
   },
   "source": [
    "### 只保存模型配置\n",
    "<!--\n",
    "### Save just the model configuration\n",
    "-->\n",
    "\n",
    "可以保存模型的配置——这样做会序列化模型的体系结构，它不保存任何权重值。即使没有最初定义模型的代码，保存的配置也可以重新创建和初始化相同的模型。Keras 支持 JSON 和 YAML 序列化格式：\n",
    "<!--\n",
    "A model's configuration can be saved—this serializes the model architecture\n",
    "without any weights. A saved configuration can recreate and initialize the same\n",
    "model, even without the code that defined the original model. Keras supports\n",
    "JSON and YAML serialization formats:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbET0oJTzGkq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_3\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_17\", \"trainable\": true, \"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_18\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize a model to JSON format\n",
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pX_badhH3yWV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'batch_input_shape': [None, 32],\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_17',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'linear',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_18',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_3'},\n",
      " 'keras_version': '2.2.4-tf'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "pprint.pprint(json.loads(json_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7CIa05r4yTb"
   },
   "source": [
    "从 JSON 重新创建模型（重新初始化）：\n",
    "<!--\n",
    "Recreate the model (newly initialized) from the JSON:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9UFv9k00E2_"
   },
   "outputs": [],
   "source": [
    "fresh_model = tf.keras.models.model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5NHtICh4uHK"
   },
   "source": [
    "要想将一个模型序列化为 YAML 格式，你必须*在导入 TensorFlow 之前*安装 `pyyaml`：\n",
    "<!--\n",
    "Serializing a model to YAML format requires that you install `pyyaml` *before you import TensorFlow*:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj24KB3Z36S4"
   },
   "outputs": [],
   "source": [
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O53Kerfl43v7"
   },
   "source": [
    "从 YAML 重新创建模型：\n",
    "<!--\n",
    "Recreate the model from the YAML:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77yRuwg03_MG"
   },
   "outputs": [],
   "source": [
    "fresh_model = tf.keras.models.model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPvOSSzM0E3B"
   },
   "source": [
    "注意：子类化模型是不可被序列化的，因为它们的结构是由 `call` 方法中的 Python 代码定义的。\n",
    "<!--\n",
    "Caution: Subclassed models are not serializable because their architecture is\n",
    "defined by the Python code in the body of the `call` method.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iu8qMwld4-71"
   },
   "source": [
    "### 在单个文件中保存整个模型\n",
    "<!--\n",
    "### Save the entire model in one file\n",
    "-->\n",
    "\n",
    "整个模型可以被保存到一个文件中，该文件包含权重值，模型的配置，甚至优化器的配置。这使您可以为模型创建 checkpoint，并在稍后从完全相同的状态恢复训练，而无需访问原始代码。\n",
    "<!--\n",
    "The entire model can be saved to a file that contains the weight values, the\n",
    "model's configuration, and even the optimizer's configuration. This allows you\n",
    "to checkpoint a model and resume training later—from the exact same\n",
    "state—without access to the original code.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45oNY34Z0E3C"
   },
   "outputs": [],
   "source": [
    "# Create a simple model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(10, activation='relu', input_shape=(32,)),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model')\n",
    "\n",
    "# Recreate the exact same model, including weights and optimizer.\n",
    "model = tf.keras.models.load_model('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGVBURDtI_I6"
   },
   "source": [
    "要想了解更多关于保存和序列化 Keras 模型的知识，请参看[保存和序列化模型](./save_and_serialize.ipynb)的指南。\n",
    "<!--\n",
    "Learn more about saving and serialization for Keras models in the guide to [save and serialize models](./save_and_serialize.ipynb).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMOWhDOB0E3E"
   },
   "source": [
    "<a name=\"eager_execution\"></a>\n",
    "## Eager execution\n",
    "\n",
    "[Eager Execution](../eager.ipynb) 是一种可以立即运行操作的命令式编程环境。Keras 不需要此功能，但是 `tf.keras` 支持它，其对于检查程序和调试很有用。\n",
    "<!--\n",
    "[Eager execution](../eager.ipynb) is an imperative programming\n",
    "environment that evaluates operations immediately. This is not required for\n",
    "Keras, but is supported by `tf.keras` and useful for inspecting your program and\n",
    "debugging.\n",
    "-->\n",
    "\n",
    "所有的 `tf.keras` 模型构建 API 都与 eager execution 兼容。虽然可以使用 `Sequential` 和函数式 API，但 eager execution 特别有利于*模型子类化*和构建*自定义层*——即那些需要您将 forward pass 编写为代码的 API（而不是通过组装现有的层来创建模型的那些 API）。\n",
    "<!--\n",
    "All of the `tf.keras` model-building APIs are compatible with eager execution.\n",
    "And while the `Sequential` and functional APIs can be used, eager execution\n",
    "especially benefits *model subclassing* and building *custom layers*—the APIs\n",
    "that require you to write the forward pass as code (instead of the APIs that\n",
    "create models by assembling existing layers).\n",
    "-->\n",
    "\n",
    "有关将 Keras 模型与自定义训练循环和 `tf.GradientTape` 一起使用的示例，请参见 [eager execution 指南](../eager.ipynb)。 您还可以在[这里](https://www.tensorflow.org/tutorials/quickstart/advanced)找到一个完整且简短的示例。\n",
    "<!--\n",
    "See the [eager execution guide](../eager.ipynb) for\n",
    "examples of using Keras models with custom training loops and `tf.GradientTape`.\n",
    "You can also find a complete, short example [here](https://www.tensorflow.org/tutorials/quickstart/advanced).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wG3NVco5B5V"
   },
   "source": [
    "## 分布式\n",
    "<!--\n",
    "## Distribution\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PJZ6e9J5JHF"
   },
   "source": [
    "### 多 GPU\n",
    "<!--\n",
    "### Multiple GPUs\n",
    "-->\n",
    "\n",
    "`tf.keras` 模型可以使用 `tf.distribute.Strategy` 在多个 GPU 上运行。该 API 允许我们在多个 GPU 上进行分布式训练，为此几乎无需更改现有代码。\n",
    "<!--\n",
    "`tf.keras` models can run on multiple GPUs using\n",
    "`tf.distribute.Strategy`. This API provides distributed\n",
    "training on multiple GPUs with almost no changes to existing code.\n",
    "-->\n",
    "\n",
    "当前 `tf.distribute.MirroredStrategy` 是唯一受支持的分布式策略。`MirroredStrategy` 在单台机器上使用 all-reduce 进行同步训练，从而实现图形内复制。要使用 `distribute.Strategy`，请将优化器的实例化以及模型的构建和编译嵌套在 `Strategy` 的 `.scope()`中，然后训练模型。\n",
    "<!--\n",
    "Currently, `tf.distribute.MirroredStrategy` is the only supported\n",
    "distribution strategy. `MirroredStrategy` does in-graph replication with\n",
    "synchronous training using all-reduce on a single machine. To use\n",
    "`distribute.Strategy`s , nest the optimizer instantiation and model construction and compilation in a `Strategy`'s `.scope()`, then\n",
    "train the model.\n",
    "-->\n",
    "\n",
    "下面的示例将 `tf.keras.Model` 分布在一台机器上的多个 GPU 中。\n",
    "<!--\n",
    "The following example distributes a `tf.keras.Model` across multiple GPUs on a\n",
    "single machine.\n",
    "-->\n",
    "\n",
    "首先，在分布式策略的 scope 内定义一个模型：\n",
    "<!--\n",
    "First, define a model inside the distributed strategy scope:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbaRr7g-0E3I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(10,)))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(0.2)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rO9MiL6X0E3O"
   },
   "source": [
    "然后，向通常一样使用数据训练模型：\n",
    "<!--\n",
    "Next, train the model on data as usual:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEwFq4PM0E3P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 32 steps\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbf5a1e4d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random((1024, 10))\n",
    "y = np.random.randint(2, size=(1024, 1))\n",
    "x = tf.cast(x, tf.float32)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6BXU5F90E3U"
   },
   "source": [
    "要想了解更多信息，请参见[TensorFlow 中分布式训练的完整指南](../distributed_training.ipynb)。\n",
    "<!--\n",
    "For more information, see the [full guide on Distributed Training in TensorFlow](../distributed_training.ipynb).\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "overview.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ml3.7': conda)",
   "language": "python",
   "name": "python37664bitml37conda9788b470732f428081b5a7a4da6890a8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
