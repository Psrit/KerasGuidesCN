{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zMKQx6DkKwt"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "J307vsiDkMMW"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCMYwDIE9dTT"
   },
   "source": [
    "# The Keras functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAJfkZ-K9flj"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/functional\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/functional.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/keras/functional.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/keras/functional.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITh3wzORxgpw"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFbM9dcfxh4l"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZI47-lpfkZ5c"
   },
   "source": [
    "## 介绍\n",
    "<!--\n",
    "## Introduction\n",
    "-->\n",
    "\n",
    "Keras *函数式 API* 是一种比 `tf.keras.Sequential` API 更加灵活的创建模型的方法。函数式 API 可以处理具有非线性拓扑结构的模型、有共享层（shared layers）的模型以及有多个输入和输出的模型。\n",
    "<!--\n",
    "The Keras *functional API* is a way to create models that is more flexible than the `tf.keras.Sequential` API. The functional API can handle models with non-linear topology, models with shared layers, and models with multiple inputs or outputs.\n",
    "-->\n",
    "\n",
    "其主要思想是深度学习的模型通常是一个由层组成的有向无环图（DAG）。因而函数式 API 是用于构建*层的图*的。\n",
    "<!--\n",
    "The main idea that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build *graphs of layers*.\n",
    "-->\n",
    "\n",
    "考虑以下模型：\n",
    "<!--\n",
    "Consider the following model:\n",
    "-->\n",
    "\n",
    "```\n",
    "(input: 784-dimensional vectors)\n",
    "       ↧\n",
    "[Dense (64 units, relu activation)]\n",
    "       ↧\n",
    "[Dense (64 units, relu activation)]\n",
    "       ↧\n",
    "[Dense (10 units, softmax activation)]\n",
    "       ↧\n",
    "(output: logits of a probability distribution over 10 classes)\n",
    "```\n",
    "\n",
    "这是一个有着三个层的很基础的图。要想使用函数式 API 构建这个模型，我们首先需要创建一个输入节点：\n",
    "<!--\n",
    "This is a basic graph with three layers. To build this model using the functional API, start by creating an input node:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yxi0LaSHkDT-"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mr3Z_Pxcnf-H"
   },
   "source": [
    "输入数据的形状被设定为一个 784 维的矢量。我们通常略去 batch size，因为只需要指定每一个采样的形状即可。\n",
    "<!--\n",
    "The shape of the data is set as a 784-dimensional vector. The batch size is always omitted since only the shape of each sample is specified.\n",
    "-->\n",
    "\n",
    "举个例子，如果你需要输入的是形状为 `(32, 32, 3)` 的图像，你可以使用：\n",
    "<!--\n",
    "If, for example, you have an image input with a shape of `(32, 32, 3)`, you would use:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-2Q2nJNneIO"
   },
   "outputs": [],
   "source": [
    "# Just for demonstration purposes.\n",
    "img_inputs = keras.Input(shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HoMFNu-pnkgF"
   },
   "source": [
    "返回的 `inputs` 包含了你的模型的输入数据的形状和 `dtype` 信息：\n",
    "<!--\n",
    "The `inputs` that is returned contains information about the shape and `dtype` of the input data that you feed to your model:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddIr9LPJnibj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 784])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZkLJeQonmTe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZnhhndTnrzC"
   },
   "source": [
    "要想在这个由层构成的图中创建一个新节点，你可以对这个 `inputs` 对象调用一个层（call a layer on this `inputs` object）：\n",
    "<!--\n",
    "You create a new node in the graph of layers by calling a layer on this `inputs` object:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMyyMTqDnpYV"
   },
   "outputs": [],
   "source": [
    "dense = layers.Dense(64, activation='relu')\n",
    "x = dense(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "besm-lgFnveV"
   },
   "source": [
    "“调用层”的操作有点像是画了一个箭头，从“inputs”指向刚刚创建的这个层。你将输入数据“传入” `dense` 层，输出数据则是 `x`。\n",
    "<!--\n",
    "The \"layer call\" action is like drawing an arrow from \"inputs\" to this layer you created.\n",
    "You're \"passing\" the inputs to the `dense` layer, and out you get `x`.\n",
    "-->\n",
    "\n",
    "让我们给这个图加入更多的层吧：\n",
    "<!--\n",
    "Let's add a few more layers to the graph of layers:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbF-MIO2ntf7"
   },
   "outputs": [],
   "source": [
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B38UlEIlnz_8"
   },
   "source": [
    "此时，你可以创建一个 `Model`，指定其输入和输出对应图中的哪些层：\n",
    "<!--\n",
    "At this point, you can create a `Model` by specifying its inputs and outputs in the graph of layers:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrSfwvl-nx9s"
   },
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJzocCbdn6qj"
   },
   "source": [
    "让我们检查一下模型概要（model summary）会给出什么内容：\n",
    "<!--\n",
    "Let's check out what the model summary looks like:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GirC9odQn5Ep"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mbNqYAlOn-vA"
   },
   "source": [
    "你也可以将模型以图片格式绘制出来：\n",
    "<!--\n",
    "You can also plot the model as a graph:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYh2wLain8Oi"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'my_first_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QtgX2RoGoDZo"
   },
   "source": [
    "而且还可以显示所绘制的图中每一层输入输出的形状：\n",
    "<!--\n",
    "And, optionally, display the input and output shapes of each layer in the plotted graph:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FGesSSuoAG5"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'my_first_model_with_shape_info.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBZ9XE6LoWvi"
   },
   "source": [
    "这张图和上面的代码几乎等同。在代码中，层之间的连接尖头为调用操作所替代。\n",
    "<!--\n",
    "This figure and the code are almost identical. In the code version, the connection arrows are replaced by the call operation.\n",
    "-->\n",
    "\n",
    "“层的图”是对深度学习模型的一种直观思维表达，而函数式 API 正是采用这样的思路来创建模型的。\n",
    "<!--\n",
    "A \"graph of layers\" is an intuitive mental image for a deep learning model, and the functional API is a way to create models that closely mirror this.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUUHMaKLoZDn"
   },
   "source": [
    "## 训练，评估和推断\n",
    "<!--\n",
    "## Training, evaluation, and inference\n",
    "-->\n",
    "\n",
    "对使用函数式 API 创建的模型进行训练、评估和推断，与 `Sequential` 模型是完全一样的。\n",
    "<!--\n",
    "Training, evaluation, and inference work exactly in the same way for models built using the functional API as for `Sequential` models.\n",
    "-->\n",
    "\n",
    "在这里，我们加载 MNIST 图像数据，将它们转变为矢量，在这些数据上拟合模型（同时在其中划分出来的验证数据集上监测模型性能），然后在测试数据集上评估模型：\n",
    "<!--\n",
    "Here, load the MNIST image data, reshape it into vectors, fit the model on the data (while monitoring performance on a validation split), then evaluate the model on the test data:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnHvkD22oFEY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 43us/sample - loss: 0.3588 - accuracy: 0.8980 - val_loss: 0.1894 - val_accuracy: 0.9452\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 1s 29us/sample - loss: 0.1712 - accuracy: 0.9504 - val_loss: 0.1586 - val_accuracy: 0.9522\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 1s 27us/sample - loss: 0.1251 - accuracy: 0.9624 - val_loss: 0.1246 - val_accuracy: 0.9643\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 1s 26us/sample - loss: 0.1001 - accuracy: 0.9696 - val_loss: 0.1216 - val_accuracy: 0.9654\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 1s 29us/sample - loss: 0.0832 - accuracy: 0.9751 - val_loss: 0.1130 - val_accuracy: 0.9691\n",
      "10000/10000 - 0s - loss: 0.1029 - accuracy: 0.9690\n",
      "Test loss: 0.10286470510240178\n",
      "Test accuracy: 0.969\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer=keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3nq2fjiLCkE"
   },
   "source": [
    "对于进一步的阅读资料，参见[训练和评估](./train_and_evaluate.ipynb)指南。\n",
    "<!--\n",
    "For further reading, see the [train and evaluate](./train_and_evaluate.ipynb) guide.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOsL56zDorLh"
   },
   "source": [
    "## 保存和序列化\n",
    "<!--\n",
    "## Save and serialize\n",
    "-->\n",
    "\n",
    "对使用函数式 API 构建的模型进行保存和序列化的过程，与 `Sequential` 模型完全一致。保存一个函数式模型的标准方法是调用 `model.save()` 来将这整个模型保存为单个文件。在之后你可以使用这个文件重建出一样的模型，哪怕当初搭建这个模型的代码已无处可寻。\n",
    "<!--\n",
    "Saving the model and serialization work the same way for models built using the functional API as they do for `Sequential` models. The standard way to save a functional model is to call `model.save()` to save the entire model as a single file. You can later recreate the same model from this file, even if the code that built the model is no longer available.\n",
    "-->\n",
    "\n",
    "这个被保存的文件包括了：\n",
    "- 模型架构\n",
    "- 模型权重值（它们是在训练过程中需要被学习的对象）\n",
    "- 训练模型的配置（如果存在的话；它们是被传递给 `compile` 的参数）\n",
    "- 优化器及其状态（如果存在的话；若你将它们遗漏，那么训练需要从头开始）\n",
    "\n",
    "<!--\n",
    "This saved file includes the:\n",
    "- model architecture\n",
    "- model weight values (that were learned during training)\n",
    "- model training config, if any (as passed to `compile`)\n",
    "- optimizer and its state, if any (to restart training where you left off)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kN-AO7xvobtr"
   },
   "outputs": [],
   "source": [
    "model.save('path_to_my_model')\n",
    "del model\n",
    "# Recreate the exact same model purely from the file:\n",
    "model = keras.models.load_model('path_to_my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0J0tFPHK4pb"
   },
   "source": [
    "要想了解更多细节，请阅读模型的[保存和序列化](./save_and_serialize.ipynb)指南。\n",
    "<!--\n",
    "For details, read the model [save and serialize](./save_and_serialize.ipynb) guide.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKz1WWr2LUzF"
   },
   "source": [
    "## 使用相同的层的图来定义多个模型\n",
    "<!--\n",
    "## Use the same graph of layers to define multiple models\n",
    "-->\n",
    "\n",
    "在函数式 API 中，我们通过在一张层的图（a graph of layers）中指定模型的输入和输出来创建我们的模型。这意味着同一张层的图可以用来生成多个模型。\n",
    "<!--\n",
    "In the functional API, models are created by specifying their inputs and outputs in a graph of layers. That means that a single graph of layers can be used to generate multiple models.\n",
    "-->\n",
    "\n",
    "在下面的例子中，你将使用同样的层结构来初始化两个模型：一个将图像输入转换为 16 维矢量的 `encoder` 模型，以及一个用于训练的端到端的（end-to-end）`autoencoder` 模型。\n",
    "<!--\n",
    "In the example below, you use the same stack of layers to instantiate two models: an `encoder` model that turns image inputs into 16-dimensional vectors,\n",
    "and an end-to-end `autoencoder` model for training.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WItZQr6LuVbF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNeg3WWFuYZK"
   },
   "source": [
    "这里，解码的层次结构与编码的层次结构严格对称，故输出层的形状和输入层的形状相同，均为 `(28, 28, 1)`。\n",
    "<!--\n",
    "Here, the decoding architecture is strictly symmetrical to the encoding architecture, so the output shape is the same as the input shape `(28, 28, 1)`.\n",
    "-->\n",
    "\n",
    "一个 `Conv2D` 层的逆是一个 `Conv2DTranspose` 层，而 `MaxPooling2D` 层的逆是 `UpSampling2D` 层。\n",
    "<!--\n",
    "The reverse of a `Conv2D` layer is a `Conv2DTranspose` layer, and the reverse of a `MaxPooling2D` layer is an `UpSampling2D` layer.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h1FVW4j-uc6Y"
   },
   "source": [
    "## 所有的模型都是可调用的，就像层一样\n",
    "<!--\n",
    "## All models are callable, just like layers\n",
    "-->\n",
    "\n",
    "你可以将任何模型看作是一个层，并将其作用于一个 `Input` 层，或者作用于另一个层的输出。调用一个模型时，你不仅仅是重用了模型的层次结构，你还重用了它所有权重值。\n",
    "<!--\n",
    "You can treat any model as if it were a layer by invoking it on an `Input` or on the output of another layer. By calling a model you aren't just reusing the architecture of the model, you're also reusing its weights.\n",
    "-->\n",
    "\n",
    "要想在实践中认识这一点，我们换一个角度来看自编码器的例子：我们创建一个编码器模型，一个解码器模型，然后在两次调用中将它们链接起来，从而得到自编码器模型：\n",
    "<!--\n",
    "To see this in action, here's a different take on the autoencoder example that creates an encoder model, a decoder model, and chain them in two calls to obtain the autoencoder model:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ld7KdsQ_uZbr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "original_img (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 9,569\n",
      "Trainable params: 9,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                18672     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         9569      \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name='original_img')\n",
    "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(16,), name='encoded_img')\n",
    "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icQFny_huiXC"
   },
   "source": [
    "正如你所见，模型可以被嵌套：一个模型可以包含子模型（因为一个模型就像是一个层一样）。模型嵌套的一个常见用途是 `ensembling`（集成学习）。例如，下面的代码将一组模型集成（ensemble）为一个模型，其输出为这组模型预测值的平均值：\n",
    "<!--\n",
    "As you can see, the model can be nested: a model can contain sub-models (since a model is just like a layer). A common use case for model nesting is *ensembling*. For example, here's how to ensemble a set of models into a single model that averages their predictions:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBlZbRn5uk-9"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(128,))\n",
    "    outputs = layers.Dense(1)(inputs)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "model1 = get_model()\n",
    "model2 = get_model()\n",
    "model3 = get_model()\n",
    "\n",
    "inputs = keras.Input(shape=(128,))\n",
    "y1 = model1(inputs)\n",
    "y2 = model2(inputs)\n",
    "y3 = model3(inputs)\n",
    "outputs = layers.average([y1, y2, y3])\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1za1TZxuoId"
   },
   "source": [
    "## 操作复杂的图拓扑结构\n",
    "<!--\n",
    "## Manipulate complex graph topologies\n",
    "-->\n",
    "\n",
    "### 有多个输入和输出的模型\n",
    "<!--\n",
    "### Models with multiple inputs and outputs\n",
    "-->\n",
    "\n",
    "函数式 API 让我们能很容易地操纵多个输入和输出。这是用 `Sequential` API 不能处理的。\n",
    "<!--\n",
    "The functional API makes it easy to manipulate multiple inputs and outputs.\n",
    "This cannot be handled with the `Sequential` API.\n",
    "-->\n",
    "\n",
    "例如，假设你正在构建一个系统，它根据优先级来对订制的 issue ticket 进行排序，并将它们发送给正确的部门。这个模型有三个输入：\n",
    "\n",
    "- ticket 的标题（文本输入），\n",
    "- ticket 的文字主体（文本输入），以及\n",
    "- 用户添加的任何标签（类别输入）\n",
    "\n",
    "<!--\n",
    "For example, if you're building a system for ranking custom issue tickets by priority and routing them to the correct department, then the model will have three inputs:\n",
    "\n",
    "- the title of the ticket (text input),\n",
    "- the text body of the ticket (text input), and\n",
    "- any tags added by the user (categorical input)\n",
    "-->\n",
    "\n",
    "这个模型有两个输出：\n",
    "\n",
    "- 介于 0 和 1 之间的优先级（sigmoid 标量输出），以及\n",
    "- 应当处理这个 ticket 的部门（从部门集合中得到的 softmax 输出）。\n",
    "\n",
    "<!--\n",
    "This model will have two outputs:\n",
    "\n",
    "- the priority score between 0 and 1 (scalar sigmoid output), and\n",
    "- the department that should handle the ticket (softmax output over the set of departments).\n",
    "-->\n",
    "\n",
    "使用函数式 API，你可以用几行代码构建这个模型：\n",
    "<!--\n",
    "You can build this model in a few lines with the functional API:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gt91OtzbutJy"
   },
   "outputs": [],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(shape=(None,), name='title')  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name='body')  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(shape=(num_tags,), name='tags')  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, name='priority')(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, name='department')(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(inputs=[title_input, body_input, tags_input],\n",
    "                    outputs=[priority_pred, department_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIS7lqW0uwh-"
   },
   "source": [
    "现在绘制这个模型：\n",
    "<!--\n",
    "Now plot the model:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMij4gzhuzYV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oOyuig2Hu00p"
   },
   "source": [
    "在编译这个模型时，你可以对每个输出设定不同的 loss。你甚至可以为每个 loss 设置一个权重值——以便调节它们对整个训练 loss 的影响程度。\n",
    "<!--\n",
    "When compiling this model, you can assign different losses to each output. You can even assign different weights to each loss—to modulate their contribution to the total training loss.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Crtdpi5Uu2cX"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss=[keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                    keras.losses.CategoricalCrossentropy(from_logits=True)],\n",
    "              loss_weights=[1., 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t42Jrn0Yu5jL"
   },
   "source": [
    "因为输出层有不同的名字，你也可以像下面这样来指定 loss 函数：\n",
    "<!--\n",
    "Since the output layers have different names, you could also specify the loss like this:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPM0EwW_u6mV"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss={'priority':keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                    'department': keras.losses.CategoricalCrossentropy(from_logits=True)},\n",
    "              loss_weights=[1., 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpTx2sXnu3-W"
   },
   "source": [
    "传入输入数据和目标数据的 NumPy 数组列表来训练模型：\n",
    "<!--\n",
    "Train the model by passing lists of NumPy arrays of inputs and targets:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nB-upOoGu_k4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples\n",
      "Epoch 1/2\n",
      "1280/1280 [==============================] - 4s 3ms/sample - loss: 1.3308 - priority_loss: 0.6997 - department_loss: 3.1554\n",
      "Epoch 2/2\n",
      "1280/1280 [==============================] - 2s 1ms/sample - loss: 1.3314 - priority_loss: 0.6964 - department_loss: 3.1752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb141a01e90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype('float32')\n",
    "\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "model.fit({'title': title_data, 'body': body_data, 'tags': tags_data},\n",
    "          {'priority': priority_targets, 'department': dept_targets},\n",
    "          epochs=2,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNguhBWuvCtz"
   },
   "source": [
    "拟合时如果使用 `Dataset` 对象，该对象应当生成（yield）一个由列表组成的元组，形如 `([title_data, body_data, tags_data], [priority_targets, dept_targets])`，或者是一个由字典组成的元组，形如 `({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})`。\n",
    "<!--\n",
    "When calling fit with a `Dataset` object, it should yield either a tuple of lists like `([title_data, body_data, tags_data], [priority_targets, dept_targets])` or a tuple of dictionaries like\n",
    "`({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})`.\n",
    "-->\n",
    "\n",
    "对于更细致的解释，请参见[训练和评估](./train_and_evaluate.ipynb)指南。\n",
    "<!--\n",
    "For more detailed explanation, refer to the [training and evaluation](./train_and_evaluate.ipynb) guide.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tR0X5tTOvPyg"
   },
   "source": [
    "### 一个 ResNet 的玩具模型\n",
    "<!--\n",
    "### A toy ResNet model\n",
    "-->\n",
    "\n",
    "除了有着多个输入和输出的模型外，函数式 API 还让我们可以很容易地处理非线性连接的拓扑结构——即那些不是顺序连接的层，而这是 `Sequential` API 所不能处理的。\n",
    "<!--\n",
    "In addition to models with multiple inputs and outputs, the functional API makes it easy to manipulate non-linear connectivity topologies—these are models with layers that are not connected sequentially. Something the `Sequential` API can not handle.\n",
    "-->\n",
    "\n",
    "这种结构常见的例子是 residual connections。让我们为 CIFAR10 构建一个 ResNet “玩具”模型以作为演示：\n",
    "<!--\n",
    "A common use case for this is residual connections. Let's build a toy ResNet model for CIFAR10 to demonstrate this:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzMoYrMNvXrm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"toy_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 30, 30, 32)   896         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 64)   18496       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 9, 9, 64)     36928       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 9, 9, 64)     0           conv2d_11[0][0]                  \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 9, 9, 64)     36928       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 9, 9, 64)     0           conv2d_13[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 64)     36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          16640       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           2570        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3), name='img')\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "block_1_output = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu')(block_3_output)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name='toy_resnet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISQX32bgrkis"
   },
   "source": [
    "绘制这个模型：\n",
    "<!--\n",
    "Plot the model:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNFVkAd3rlCM"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'mini_resnet.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECcG87yZrxp5"
   },
   "source": [
    "现在训练这个模型：\n",
    "<!--\n",
    "Now train the model:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_iXGz5XEryou"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQfg0JUkr7SH"
   },
   "source": [
    "## 共享层\n",
    "<!--\n",
    "## Shared layers\n",
    "-->\n",
    "\n",
    "函数式 API 另一个很好的用处是用来构建使用*共享层*的模型。共享层指的是在同一个模型中被重用多次的层实例——它们学习那些在层的图中不同路径所对应的特征。\n",
    "<!--\n",
    "Another good use for the functional API are for models that use *shared layers*. Shared layers are layer instances that are reused multiple times in a same model—they learn features that correspond to multiple paths in the graph-of-layers.\n",
    "-->\n",
    "\n",
    "共享层常用于编码来自相似空间的输入（例如，具有相似词汇的两段不同的文本）。它们使得这些不同的输入之间可以共享信息，并让我们有可能使用更少的数据来训练这样的模型。如果在其中一个输入中看到了某个单词，那么所有经过该共享层的输入数据的处理都将从中获益。\n",
    "<!--\n",
    "Shared layers are often used to encode inputs from similar spaces (say, two different pieces of text that feature similar vocabulary). They enable sharing of information across these different inputs, and they make it possible to train such a model on less data. If a given word is seen in one of the inputs, that will benefit the processing of all inputs that pass through the shared layer.\n",
    "-->\n",
    "\n",
    "要想在函数式 API 中共享一个层，只需多次调用那个层即可。例如，下面是一个在两个不同文本输入之间共享的 `Embedding` 层：\n",
    "<!--\n",
    "To share a layer in the functional API, call the same layer instance multiple times. For instance, here's an `Embedding` layer shared across two different text inputs:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9pAPQCnKuMR"
   },
   "outputs": [],
   "source": [
    "# Embedding for 1000 unique words mapped to 128-dimensional vectors\n",
    "shared_embedding = layers.Embedding(1000, 128)\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_a = keras.Input(shape=(None,), dtype='int32')\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_b = keras.Input(shape=(None,), dtype='int32')\n",
    "\n",
    "# Reuse the same layer to encode both inputs\n",
    "encoded_input_a = shared_embedding(text_input_a)\n",
    "encoded_input_b = shared_embedding(text_input_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNEKvfUpr-Kf"
   },
   "source": [
    "## 提取和重用层的图中的节点\n",
    "<!--\n",
    "## Extract and reuse nodes in the graph of layers\n",
    "-->\n",
    "\n",
    "因为你正在操作的层的图是静态的数据结构，所以它能被访问和检查。这也正是为什么你能将函数式模型绘制为图片的原因。\n",
    "<!--\n",
    "Because the graph of layers you are manipulating is a static data structure, it can be accessed and inspected. And this is how you are able to plot functional models as images.\n",
    "-->\n",
    "\n",
    "这也意味着你能访问中间层（图中的“节点”）的激活函数并在其他地方重用它们——这对于特征提取等工作非常有用。\n",
    "<!--\n",
    "This also means that you can access the activations of intermediate layers (\"nodes\" in the graph) and reuse them elsewhere—which is very useful for something like feature extraction.\n",
    "-->\n",
    "\n",
    "让我们看一个例子。这是一个 VGG19 模型，其权重已经通过在 ImageNet 上预训练得到：\n",
    "<!--\n",
    "Let's look at an example. This is a VGG19 model with weights pretrained on ImageNet:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-gl3xHBH-oX"
   },
   "outputs": [],
   "source": [
    "vgg19 = tf.keras.applications.VGG19()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKefin_xIGBP"
   },
   "source": [
    "下面是模型内部各层的激活函数，只需查询图数据结构就可以得到：\n",
    "<!--\n",
    "And these are the intermediate activations of the model, obtained by querying the graph data structure:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_Ap05fgIRgE"
   },
   "outputs": [],
   "source": [
    "features_list = [layer.output for layer in vgg19.layers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1zx5qM7IYu4"
   },
   "source": [
    "使用这些特征来创建一个新的特征提取模型，其返回的是各个中间层激活函数的值：\n",
    "<!--\n",
    "Use these features to create a new feature-extraction model that returns the values of the intermediate layer activations:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrU82Pa8Igwo"
   },
   "outputs": [],
   "source": [
    "feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)\n",
    "\n",
    "img = np.random.random((1, 224, 224, 3)).astype('float32')\n",
    "extracted_features = feat_extraction_model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-e2-jNCLIqy"
   },
   "source": [
    "这对于诸如[神经样式转换（neural style transfer）](https://www.tensorflow.org/tutorials/generative/style_transfer)之类的任务非常有用。\n",
    "<!--\n",
    "This comes in handy for tasks like [neural style transfer](https://www.tensorflow.org/tutorials/generative/style_transfer), among other things.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9M2Uvi3sBy0"
   },
   "source": [
    "## 使用自定义的层来扩展 API\n",
    "<!--\n",
    "## Extend the API using custom layers\n",
    "-->\n",
    "\n",
    "`tf.keras` 囊括了很多种内置的层，例如：\n",
    "\n",
    "- 卷积层：`Conv1D`，`Conv2D`，`Conv3D`，`Conv2DTranspose`\n",
    "- 池化层：`MaxPooling1D`，`MaxPooling2D`，`MaxPooling3D`，`AveragePooling1D`\n",
    "- RNN 层：`GRU`，`LSTM`，`ConvLSTM2D`\n",
    "- `BatchNormalization`，`Dropout`，`Embedding`等等。\n",
    "\n",
    "<!--\n",
    "`tf.keras` includes a wide range of built-in layers, for example:\n",
    "\n",
    "- Convolutional layers: `Conv1D`, `Conv2D`, `Conv3D`, `Conv2DTranspose`\n",
    "- Pooling layers: `MaxPooling1D`, `MaxPooling2D`, `MaxPooling3D`, `AveragePooling1D`\n",
    "- RNN layers: `GRU`, `LSTM`, `ConvLSTM2D`\n",
    "- `BatchNormalization`, `Dropout`, `Embedding`, etc.\n",
    "-->\n",
    "\n",
    "但是如果从中找不到你所需要的层，你可以轻而易举地创建你自己的层来扩展 API。所有的层继承自 `Layer` 类，并且实现：\n",
    "\n",
    "- `call` 方法，定义该层所完成的计算工作。\n",
    "- `build` 方法，为该层创建权重参数（这只是代码风格的约定，因为你还可以在 `__init__` 里创建权重）。\n",
    "\n",
    "<!--\n",
    "But if you don't find what you need, it's easy to extend the API by creating your own layers. All layers subclass the `Layer` class and implement:\n",
    "\n",
    "- `call` method, that specifies the computation done by the layer.\n",
    "- `build` method, that creates the weights of the layer (this is just a style convention since you can create weights in `__init__`, as well).\n",
    "-->\n",
    "\n",
    "要想了解更多关于从头创建层的知识，请参阅[自定义层和模型](./custom_layers_and_models.ipynb)指南。\n",
    "<!--\n",
    "To learn more about creating layers from scratch, read [custom layers and models](./custom_layers_and_models.ipynb) guide.\n",
    "-->\n",
    "\n",
    "下面是对 `tf.keras.layers.Dense` 的一个基本实现：\n",
    "<!--\n",
    "The following is a basic implementation of `tf.keras.layers.Dense`:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztAmarbgNV6V"
   },
   "outputs": [],
   "source": [
    "class CustomDense(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "\n",
    "inputs = keras.Input((4,))\n",
    "outputs = CustomDense(10)(inputs)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXxp_32bNWTy"
   },
   "source": [
    "若要使你的自定义层支持序列化，定义一个 `get_config` 方法，其返回层实例的构造函数参数：\n",
    "<!--\n",
    "For serialization support in your custom layer, define a `get_config` method that returns the constructor arguments of the layer instance:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3OQ4XxzNfAZ"
   },
   "outputs": [],
   "source": [
    "class CustomDense(layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'units': self.units}\n",
    "\n",
    "\n",
    "inputs = keras.Input((4,))\n",
    "outputs = CustomDense(10)(inputs)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "\n",
    "new_model = keras.Model.from_config(\n",
    "    config, custom_objects={'CustomDense': CustomDense})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXg6hZN_NfN8"
   },
   "source": [
    "你还可以定义类方法 `from_config(cls, config)`（可选），它被用于根据层实例的 config 字典来重建该层实例。`from_config` 的默认实现是：\n",
    "<!--\n",
    "Optionally, implement the classmethod `from_config(cls, config)` which is used when recreating a layer instance given its config dictionary. The default implementation of `from_config` is:\n",
    "-->\n",
    "\n",
    "```python\n",
    "def from_config(cls, config):\n",
    "  return cls(**config)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ifOVqn84sCNU"
   },
   "source": [
    "## 何时使用函数式 API\n",
    "<!--\n",
    "## When to use the functional API\n",
    "-->\n",
    "\n",
    "什么时候你应该使用 Keras 函数式 API 来创建一个新模型，而什么时候你又应该直接继承 `Model` 类？一般而言，函数式 API 更高级、更易用、更安全，而且拥有许多派生模型类所不支持的特性。\n",
    "<!--\n",
    "When should you use the Keras functional API to create a new model, or just subclass the `Model` class directly? In general, the functional API is higher-level, easier and safer, and has a number of features that subclassed models do not support.\n",
    "-->\n",
    "\n",
    "然而，在所构建的模型不能容易地被表达为层的有向无环图时，模型派生为我们带来了更高的便利性。例如，你不能使用函数式 API 来实现一个 Tree-RNN，而是必须直接继承 `Model`。\n",
    "<!--\n",
    "However, model subclassing provides greater flexibility when building models that are not easily expressible as directed acyclic graphs of layers. For example, you could not implement a Tree-RNN with the functional API and would have to subclass `Model` directly.\n",
    "-->\n",
    "\n",
    "对于深入解读函数式 API 和模型派生之间的区别，请阅读文章《[What are Symbolic and Imperative APIs in TensorFlow 2.0?](https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html)》。\n",
    "<!--\n",
    "For in-depth look at the differences between the functional API and model subclassing, read [What are Symbolic and Imperative APIs in TensorFlow 2.0?](https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html).\n",
    "-->\n",
    "\n",
    "### 函数式 API 的强大\n",
    "<!--\n",
    "### Functional API strengths\n",
    "-->\n",
    "\n",
    "以下性质 `Sequential` 模型也具备（它们都是数据结构，data structures），但是派生的模型是没有这些性质的（派生的模型是 Python 字节码，而非数据结构）。\n",
    "<!--\n",
    "The following properties are also true for Sequential models (which are also data structures), but are not true for subclassed models (which are Python bytecode, not data structures).\n",
    "-->\n",
    "\n",
    "#### 更简洁\n",
    "<!--\n",
    "#### Less verbose\n",
    "-->\n",
    "\n",
    "使用函数式 API，无须编写 `super(MyClass, self).__init__(...)`、`def call(self, ...):` 等代码。\n",
    "<!--\n",
    "There is no `super(MyClass, self).__init__(...)`, no `def call(self, ...):`, etc.\n",
    "-->\n",
    "\n",
    "比较一下：\n",
    "<!--\n",
    "Compare:\n",
    "-->\n",
    "\n",
    "```python\n",
    "inputs = keras.Input(shape=(32,))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "outputs = layers.Dense(10)(x)\n",
    "mlp = keras.Model(inputs, outputs)\n",
    "```\n",
    "\n",
    "而派生版如下：\n",
    "<!--\n",
    "With the subclassed version:\n",
    "-->\n",
    "\n",
    "```python\n",
    "class MLP(keras.Model):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.dense_1 = layers.Dense(64, activation='relu')\n",
    "        self.dense_2 = layers.Dense(10)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "\n",
    "# Instantiate the model.\n",
    "mlp = MLP()\n",
    "# Necessary to create the model's state.\n",
    "# The model doesn't have a state until it's called at least once.\n",
    "_ = mlp(tf.zeros((1, 32)))\n",
    "```\n",
    "\n",
    "#### 在定义时就检查模型\n",
    "<!--\n",
    "#### Model validation while defining\n",
    "-->\n",
    "\n",
    "在函数式 API 中，输入数据的格式（形状和 dtype）是（通过 `Input`）提前被创建好的。每次你调用一个层，它都会检查传递给它的数据格式是否与预先的假设相匹配。如果不匹配，它会抛出一条有价值的错误信息。\n",
    "<!--\n",
    "In the functional API, the input specification (shape and dtype) is created in advance (using `Input`). Every time you call a layer, the layer checks that the specification passed to it matches its assumptions, and it will raise a helpful error message if not.\n",
    "-->\n",
    "\n",
    "这保证了你使用函数式 API 创建的任何模型都能正常运行。除了与模型收敛性相关的调试外，所有调试都在模型构建过程中静态地发生，而不是在执行时发生。这类似于编译器中的类型检查。\n",
    "<!--\n",
    "This guarantees that any model you can build with the functional API will run. All debugging—other than convergence-related debugging—happens statically during the model construction and not at execution time. This is similar to type checking in a compiler.\n",
    "-->\n",
    "\n",
    "#### 函数式模型可以被绘图和访问\n",
    "<!--\n",
    "#### A functional model is plottable and inspectable\n",
    "-->\n",
    "\n",
    "你可以将函数式模型作为一张图绘制出来，而且你能轻而易举地访问图内部的节点。例如，要想提取出中间层的激活函数并重用它们，你可以像这样（和上文中的例子一样）：\n",
    "<!--\n",
    "You can plot the model as a graph, and you can easily access intermediate nodes in this graph. For example, to extract and reuse the activations of intermediate layers (as seen in a previous example):\n",
    "-->\n",
    "\n",
    "```python\n",
    "features_list = [layer.output for layer in vgg19.layers]\n",
    "feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)\n",
    "```\n",
    "\n",
    "#### 函数式模型可以被序列化和复制\n",
    "<!--\n",
    "#### A functional model can be serialized or cloned\n",
    "-->\n",
    "\n",
    "因为函数式模型是一个数据结构而非一段代码，所以我们可以很容易地将其安全地序列化并存储为一个文件，我们可以使用这个文件重建出完全相同的模型，而无需拥有最原始的那些代码。参见[存储和序列化指南](./save_and_serialize.ipynb)。\n",
    "<!--\n",
    "Because a functional model is a data structure rather than a piece of code, it is safely serializable and can be saved as a single file that allows you to recreate the exact same model without having access to any of the original code. See the [saving and serialization guide](./save_and_serialize.ipynb).\n",
    "-->\n",
    "\n",
    "\n",
    "### 函数式 API 的弱点\n",
    "<!--\n",
    "### Functional API weakness\n",
    "-->\n",
    "\n",
    "#### 不支持动态结构\n",
    "<!--\n",
    "#### Does not support dynamic architectures\n",
    "-->\n",
    "\n",
    "函数式 API 将模型当作层的有向无环图来处理。这对于大部分深度学习结构而言都是成立的，但也存在例外——例如，递归网络和 Tree RNN 不遵循此假设，因此无法使用函数式 API 实现。\n",
    "<!--\n",
    "The functional API treats models as DAGs of layers. This is true for most deep learning architectures, but not all—for example, recursive networks or Tree RNNs do not follow this assumption and cannot be implemented in the functional API.\n",
    "-->\n",
    "\n",
    "#### 一切从头创建\n",
    "<!--\n",
    "#### Everything from scratch\n",
    "-->\n",
    "\n",
    "在编写高级结构时，你可能想要做一些有意思的事，而不仅仅是定义一个层的有向无环图。例如，要想在你的模型实例上开放多种自定义的训练和推断方法（to expose multiple custom training and inference methods on your model instance），你必须使用模型派生。\n",
    "<!--\n",
    "When writing advanced architectures, you may want to do things that are outside the scope of defining a DAG of layers. For example, you must use model subclassing to expose multiple custom training and inference methods on your model instance.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ym1jrCqusGvj"
   },
   "source": [
    "## 混合-匹配 API 风格\n",
    "<!--\n",
    "## Mix-and-match API styles\n",
    "-->\n",
    "\n",
    "选择函数式 API 还是模型继承并不是一个二元的决定，这不会限制你只能使用它们当中的一种模型。`tf.keras` API 中的所有模型都可以搭配使用，无论它们是 `Sequential` 模型，函数式模型，还是从头编写的派生模型。\n",
    "<!--\n",
    "Choosing between the functional API or Model subclassing isn't a binary decision that restricts you into one category of models. All models in the `tf.keras` API can interact with each other, whether they're `Sequential` models, functional models, or subclassed models that are written from scratch.\n",
    "-->\n",
    "\n",
    "你始终可以将函数式模型或 `Sequential` 模型当作派生模型/派生层的一部分来使用：\n",
    "<!--\n",
    "You can always use a functional model or `Sequential` model as part of a subclassed model or layer:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zF5YTLy_vGZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 32)\n"
     ]
    }
   ],
   "source": [
    "units = 32\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "\n",
    "# Define a Functional model\n",
    "inputs = keras.Input((None, units))\n",
    "x = layers.GlobalAveragePooling1D()(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "class CustomRNN(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.units = units\n",
    "        self.projection_1 = layers.Dense(units=units, activation='tanh')\n",
    "        self.projection_2 = layers.Dense(units=units, activation='tanh')\n",
    "        # Our previously-defined Functional model\n",
    "        self.classifier = model\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
    "        for t in range(inputs.shape[1]):\n",
    "            x = inputs[:, t, :]\n",
    "            h = self.projection_1(x)\n",
    "            y = h + self.projection_2(state)\n",
    "            state = y\n",
    "            outputs.append(y)\n",
    "        features = tf.stack(outputs, axis=1)\n",
    "        print(features.shape)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "rnn_model = CustomRNN()\n",
    "_ = rnn_model(tf.zeros((1, timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxW1d0a8_ufg"
   },
   "source": [
    "你也可以在函数式 API 中使用任意派生层或者派生模型，只要其以如下之一的方式实现 `call` 方法：\n",
    "\n",
    "- `call(self, inputs, **kwargs)`：`inputs` 是一个张量，或者张量组成的潜逃结构（例如一个张量列表）；`**kwargs` 是非张量（非输入数据）的函数参数。\n",
    "- `call(self, inputs, training=None, **kwargs)`：`training` 是一个布尔值，指定该层应当以训练模式还是以推断模式运行。\n",
    "- `call(self, inputs, mask=None, **kwargs)`：`mask` 是一个布尔值组成的掩码张量（在诸如 RNN 之类的情况下有用）。\n",
    "- `call(self, inputs, training=None, mask=None, **kwargs)`：显而易见，这种定义方式将掩码和训练时的行为同时给定。\n",
    "\n",
    "<!--\n",
    "You can use any subclassed layer or model in the functional API as long as it implements a `call` method that follows one of the following patterns:\n",
    "\n",
    "- `call(self, inputs, **kwargs)`  —Where `inputs` is a tensor or a nested structure of tensors (e.g. a list of tensors), and where `**kwargs` are non-tensor arguments (non-inputs).\n",
    "- `call(self, inputs, training=None, **kwargs)` —Where `training` is a boolean indicating whether the layer should behave in training mode and inference mode.\n",
    "- `call(self, inputs, mask=None, **kwargs)` —Where `mask` is a boolean mask tensor (useful for RNNs, for instance).\n",
    "- `call(self, inputs, training=None, mask=None, **kwargs)` —Of course, you can have both masking and training-specific behavior at the same time.\n",
    "-->\n",
    "\n",
    "此外，如果你在你的自定义层/模型中实现了 `get_config` 方法，那么你基于它们创建的函数式模型仍然是可序列化和可复制的。\n",
    "<!--\n",
    "Additionally, if you implement the `get_config` method on your custom Layer or model, the functional models you create will still be serializable and cloneable.\n",
    "-->\n",
    "\n",
    "下面的简单例子展示了如何在函数式模型中使用一个从头编写的自定义 RNN：\n",
    "<!--\n",
    "Here's a quick example of a custom RNN written from scratch in a functional model:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmTEZ6F3ArJR"
   },
   "outputs": [],
   "source": [
    "units = 32\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "class CustomRNN(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.units = units\n",
    "        self.projection_1 = layers.Dense(units=units, activation='tanh')\n",
    "        self.projection_2 = layers.Dense(units=units, activation='tanh')\n",
    "        self.classifier = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
    "        for t in range(inputs.shape[1]):\n",
    "            x = inputs[:, t, :]\n",
    "            h = self.projection_1(x)\n",
    "            y = h + self.projection_2(state)\n",
    "            state = y\n",
    "            outputs.append(y)\n",
    "        features = tf.stack(outputs, axis=1)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "# Note that you specify a static batch size for the inputs with the `batch_shape`\n",
    "# arg, because the inner computation of `CustomRNN` requires a static batch size\n",
    "# (when you create the `state` zeros tensor).\n",
    "inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim))\n",
    "x = layers.Conv1D(32, 3)(inputs)\n",
    "outputs = CustomRNN()(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "rnn_model = CustomRNN()\n",
    "_ = rnn_model(tf.zeros((1, 10, 5)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "functional.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ml3.7': conda)",
   "language": "python",
   "name": "python37664bitml37conda9788b470732f428081b5a7a4da6890a8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
